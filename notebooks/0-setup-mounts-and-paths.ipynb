{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d924710-b55a-4386-9e16-c6cf24f1dd64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì¶ Setup Mounts And Paths\n",
    "### üß∞ Importing project helper functions\n",
    "\n",
    "In this project, we‚Äôve organized common setup and data generation logic into a separate **`helpers`** module.  \n",
    "By importing these functions, we can keep the notebook clean and focus on the **data engineering workflow**, rather than repeating boilerplate code.\n",
    "\n",
    "- `setup_schemas` ‚Äì creates and configures the database schemas used in this project.  \n",
    "- `setup_volumes` ‚Äì sets up Unity Catalog volumes where data files will be stored.  \n",
    "- `generate_user_data` ‚Äì generates realistic synthetic user data.  \n",
    "- `generate_product_data` ‚Äì generates product catalog data with daily updates.  \n",
    "- `generate_sales_data` ‚Äì generates transactional sales data with inserts, updates, and deletes.\n",
    "\n",
    "This modular approach makes the pipeline easier to **maintain**, **reuse**, and **extend**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5693847-76e0-44e5-b3c3-1e5b84cb4d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from helpers import setup_schemas, setup_volumes, generate_batch_files as gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de6070c-efcd-4fbf-95c9-5646a04f7326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üèóÔ∏è Creating user schemas across environments\n",
    "\n",
    "This command initializes the **database schemas** (namespaces) that will structure our data in **Unity Catalog**.\n",
    "\n",
    "The function `setup_schemas.create_user_schemas()`:\n",
    "\n",
    "- Loops through the environments: `dev` and `prd`.  \n",
    "- Uses the catalog for each environment (e.g., `capstone_dev`, `capstone_prd`).  \n",
    "- Creates the schemas (if they don‚Äôt already exist) for each data layer:\n",
    "  - `bronze` ‚Äì minimally processed data.  \n",
    "  - `silver` ‚Äì cleaned and standardized datasets.  \n",
    "  - `gold` ‚Äì curated datasets ready for analytics.\n",
    "\n",
    "By creating these schemas up front, we establish a **consistent data architecture** for the entire project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe50449-779e-41af-8fff-a52be0694ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "setup_schemas.create_user_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cf04c4d-a218-4e27-b288-5575830f8eee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üóÇÔ∏è Creating Unity Catalog Volumes\n",
    "\n",
    "Once our schemas are set up, we need **volumes** to store the raw data files for each entity in the project.\n",
    "\n",
    "The function `setup_volumes.create_volumes()`:\n",
    "\n",
    "- Iterates through the environments: `dev` and `prd`.  \n",
    "- Targets the `bronze` schema in each environment (e.g., `capstone_dev.bronze`).  \n",
    "- Creates volumes for each purpose:\n",
    "  - `raw_files` ‚Äì stores generated and raw files.  \n",
    "  - `checkpoint_files` ‚Äì stores checkpoint files.  \n",
    "  - `schema_files` ‚Äì store schema files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e01c8f6a-41f2-4415-a857-b9331f436808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "setup_volumes.create_volumes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba58e92b-c7b9-4fbc-a122-63e7c8563ce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üë§ Generating synthetic user data\n",
    "\n",
    "Now that the schemas and volumes are set up, we can generate the **user dataset** for the project.\n",
    "\n",
    "The function `generate_user_data.main()`:\n",
    "\n",
    "- Creates **synthetic user records** with realistic attributes (name, email, phone, etc.).  \n",
    "- Writes the generated data to the **`user` volume** in the specified environment.  \n",
    "- We run it for both environments:\n",
    "  - `env=\"dev\"` ‚Äì for development/testing purposes.  \n",
    "  - `env=\"prd\"` ‚Äì for production-like datasets.\n",
    "\n",
    "This step populates the **raw layer** of the Lakehouse with user data, ready for downstream processing and analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47a18235-add7-492b-85d7-99f5ef6171b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gen.copy_base_files(\"users\", \"dev\")\n",
    "gen.copy_base_files(\"users\", \"prd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03b5e285-c7e1-4eb1-9fef-c525c70526cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üõçÔ∏è Generating product catalog data\n",
    "\n",
    "After generating user data, we create the **product dataset** for the project.\n",
    "\n",
    "The function `generate_product_data.main()`:\n",
    "\n",
    "- Generates a **synthetic product catalog** with attributes such as:\n",
    "  - Product ID\n",
    "  - Name\n",
    "  - Category\n",
    "  - Price\n",
    "  - Daily updates to simulate realistic changes  \n",
    "- Saves the generated data to the **`product` volume** in the specified environment.  \n",
    "- Executed for both environments:\n",
    "  - `env=\"dev\"` ‚Äì for development and testing workflows.  \n",
    "  - `env=\"prd\"` ‚Äì for production-like datasets.\n",
    "\n",
    "This step populates the **raw layer** of the Lakehouse with product data, providing a foundation for sales and event generation downstream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43bb9edd-9d6d-407b-9b91-24a87c8d5187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gen.copy_base_files(\"products\", \"dev\")\n",
    "gen.copy_base_files(\"products\", \"prd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1e5591b-4103-4615-992f-1119161eed6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí∞ Generating sales data\n",
    "\n",
    "This script creates synthetic **sales transactions** for the project, including inserts, updates, and deletes.  \n",
    "\n",
    "- First, it generates a **historical snapshot** of sales for the base date.  \n",
    "- Then, it creates **daily changes** over multiple days, simulating realistic updates and new transactions.  \n",
    "- All data is saved directly to the **`sales` volume** in the specified environment (`dev` or `prd`) using an **in-memory buffer**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90ec3c69-45a1-4ff3-b9f5-ecd92eb0ff1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gen.copy_base_files(\"sales\", \"dev\")\n",
    "gen.copy_base_files(\"sales\", \"prd\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7742140083945851,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "0-setup-mounts-and-paths",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
