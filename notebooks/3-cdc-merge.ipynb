{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "693669fb-8e7d-4acf-8f8f-4afdbaafc5dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pytest==8.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e74e9d90-2391-4b43-812a-9cd28dcddae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üßæ Module 3 ‚Äî Incremental CDC Ingestion (Sales)\n",
    "\n",
    "Building resilient pipelines with **Delta Lake MERGE** and **Auto Loader**\n",
    "\n",
    "### Learning Objectives\n",
    "In this notebook, learners will:\n",
    "- Understand **Change Data Capture (CDC)** concepts in a Lakehouse.\n",
    "- Simulate daily incremental data deliveries using generated CSVs.\n",
    "- Apply **MERGE INTO** to synchronize changes (insert, update, delete).\n",
    "- Manage **schema evolution** (new `region` column on day 4).\n",
    "- Ensure **idempotent processing** ‚Äî re-running a date shouldn‚Äôt create duplicates.\n",
    "- Validate the final Silver table.\n",
    "\n",
    "### Scenario:\n",
    "Your e-commerce system delivers **daily incremental sales extracts**:  \n",
    "- Day 0 ‚Üí Historical snapshot.  \n",
    "- Days 1‚Äì7 ‚Üí Daily delta files with inserts, updates, and deletes.  \n",
    "- On day 4 ‚Üí The schema evolves (a new column `region` is added).  \n",
    "\n",
    "Our job is to build a resilient CDC pipeline capable of handling all these changes seamlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e6b5225-44b5-46ac-aab8-919324a7c08a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 0 ‚Äî Setup and Context\n",
    "\n",
    "**TO DO:**\n",
    "\n",
    "Define common variables like \n",
    "- Volume locations: data, checkpoints and schemas.\n",
    "- Table full name (three level namespace).\n",
    "- Import python libraries if needed: e.g. `helpers.utils` package.\n",
    "\n",
    "> **Optional:**  \n",
    "> Validate data in the volumen you just created: `\"/Volumes/capstone_dev/{{you_bronze_schema}}/raw_files/\"`  \n",
    "> You can use dbutils command for that purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9eee566-edb7-4e9d-8615-10f05d64a664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from helpers import utils\n",
    "from instructors.src.solutions.cdc_merge import CDCMerge\n",
    "\n",
    "mod3 = CDCMerge()\n",
    "catalog_name = utils.get_param(\"catalog\", \"capstone_dev\")\n",
    "\n",
    "base_user = utils.get_base_user_schema()\n",
    "schema_bronze = f\"{base_user}_bronze\"\n",
    "schema_silver = f\"{base_user}_silver\"\n",
    "table_name = \"sales\"\n",
    "\n",
    "# UC Volume path for governed data\n",
    "volume_data = f\"/Volumes/{catalog_name}/{schema_bronze}/raw_files/sales\"\n",
    "volume_check = f\"/Volumes/{catalog_name}/{schema_bronze}/checkpoint_files/sales\"\n",
    "volume_schema = f\"/Volumes/{catalog_name}/{schema_bronze}/schema_files/sales\"\n",
    "full_table_bronze = f\"{catalog_name}.{schema_bronze}.{table_name}\"\n",
    "full_table_silver = f\"{catalog_name}.{schema_silver}.{table_name}\"\n",
    "\n",
    "print(f\"Source Volume Path: {volume_data}\")\n",
    "print(f\"Source Volume Checkpoints: {volume_check}\")\n",
    "print(f\"Source Volume Schema: {volume_schema}\")\n",
    "print(f\"Bronze Table: {full_table_bronze}\")\n",
    "print(f\"Silver Table: {full_table_silver}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90aa7be2-5b88-4996-ab78-5ed07f0b3731",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Validate that 8 files exist in the raw folder\n",
    "files = dbutils.fs.ls(volume_data)\n",
    "print(f\"Found {len(files)} files in {volume_data}:\")\n",
    "for f in files:\n",
    "    print(\"-\", f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3ec0632-8ba6-4dc5-9e59-8a8e3157831e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1 ‚Äî Ingest Daily Files into Bronze Layer\n",
    "\n",
    "**TO DO:**\n",
    "- Create empty table in bronze layer with expected schema.\n",
    "- Table creation is optional if autoloader is used and toTable option is active.\n",
    "- Initial schema doesn't contain the column region.\n",
    "- Copy data from the input files CSV (data volumen) into the **Bronze Delta table**.\n",
    "- You can use both `COPY INTO` or Autoloader to insert the data, both commands ensure **idempotency** ‚Äî previously loaded files won‚Äôt reload.\n",
    "- Include the `_metadata` struct (available in Auto Loader and COPY INTO), which contains file-level information such as _metadata.file_name, _metadata.file_modification_time, and _metadata.file_size. We'll use that column in future steps. https://docs.databricks.com/aws/en/ingestion/file-metadata-column \n",
    "\n",
    "**TIPS:**\n",
    "- Handle schema change / evolution on read (FORMAT_OPTIONS).\n",
    "- Enable `mergeSchema = true` option on write (COPY_OPTIONS) to gracefully handle the appearance of new columns.\n",
    "- In case of choosing autoloader, use the corresponding `checkpoint_files` and `schema_files` volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0951253b-807e-436f-865f-26e5e7fa2f85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.1 ‚Äî Create a Bronze Delta Table (OPTIONAL)\n",
    "\n",
    "| COLUMN | DATA TYPE |\n",
    "| :------- | :------: |\n",
    "| sale_id | INT |\n",
    "| product_id | INT |\n",
    "| user_id | INT |\n",
    "| qty | INT |\n",
    "| price | DOUBLE |\n",
    "| status | STRING |\n",
    "| updated_at | DATE |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "065590cf-3289-4a1a-a7f0-973a969250c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(mod3.create_bronze_sales(full_table_bronze))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "125f22fc-8264-45b3-a7f9-d5372691979f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.2 ‚Äî Copy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51813f81-0240-466c-b06b-775a3df87f29",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760459263963}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### OPTION 1\n",
    "display(mod3.copy_into_with_metadata(full_table_bronze, volume_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b657b77f-72df-485e-b1bd-9b85c6acfc1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### OPTION 2\n",
    "#display(mod3.auto_loader_with_metadata(full_table_bronze, volume_data, volume_schema, volume_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec739fd6-2c4c-47cc-964c-33b463001478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.3 ‚Äî Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbd2ce3-ce84-4eff-816f-abd2c12a81ff",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760648326706}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {full_table_bronze}\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b048a991-36e7-43e4-bedd-ac760800a2e5",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760448638272}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"DESCRIBE HISTORY {full_table_bronze}\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "919c1939-7f8b-4967-a52d-be5698e31e37",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760402547276}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"DESCRIBE TABLE {full_table_bronze}\"\n",
    "display(spark.sql(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "661cdabb-0cfd-4b0b-961a-7e1793e50573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2 ‚Äî Apply CDC Merge Logic\n",
    "\n",
    "We'll now implement the **Silver merge logic**, where each day's file is treated as an incremental CDC feed applied onto our existing table.\n",
    "\n",
    "**TO DO:**\n",
    "- Create a silver table **sales**:\n",
    "  - Add 4 additional columns **_is_active**, **_created_at**, **_updated_at** and **_file_name**.\n",
    "  - The input columns **status** and **updated_at** are not needed after the merge and should be ignored in the silver table.\n",
    "  - Rename the column qty to quantity.\n",
    "- Create a function named `cdc_merge` that simulates a daily insertion.\n",
    "  - This function should receive 3 parameters `full_table_bronze`, `full_table_silver`, and a string `filter_date` parameter with format ('YYYY-MM-DD').\n",
    "  - Filter the bronze table by using the `filter_date` on the `updated_at` column for a single day increment, and perform a `MERGE INTO` operation into the silver table. You can use an intermediate temporary table for that purpose.\n",
    "- Execute the function iteratively **per day** in order to simulate historical load and incremental updates.\n",
    "\n",
    "**MERGE INTO - DETAIL**  \n",
    "\n",
    "- The status column identifies the operation to perform (Update, Delete, Insert).\n",
    "- We want to keep all sales, even after deletion by using the **_is_active** column.\n",
    "- **INSERT:** new records.\n",
    "  - The new columns **_created_at** and **_updated_at** should be populated with the **updated_at** value.\n",
    "  - **_is_active** should be true at insertion.\n",
    "  - **_file_name** should be extracted from the metadata struct (_metadata.file_name).\n",
    "- **UPDATE:** modified columns (**quantity**, **price**, **region** and **_updated_at**).\n",
    "- **DELETE:** Mark deleted records as inactive (`is_active = false`) and set new value of **_updated_at**.\n",
    "- You should guarantee `Idempotency, It means if we run the data merge again for the same already processed dates, the result should't change. You can use  **_updated_at** column to achieve that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abadf40d-37d8-4da7-897b-d0a13a484064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 ‚Äî Create a Silver Delta Table\n",
    "\n",
    "| COLUMN | DATA TYPE |\n",
    "| :------- | :------: |\n",
    "| sale_id | INT |\n",
    "| product_id | INT |\n",
    "| user_id | INT |\n",
    "| quantity | INT |\n",
    "| price | DOUBLE |\n",
    "| region | STRING |\n",
    "| (new columns) ... | ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "627ef1e9-0d75-4b5d-9142-176d0f3240df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(mod3.create_silver_sales(full_table_silver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1eb6b0c-8726-4e6d-aaec-228b4dc343dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 ‚Äî Create CDC merge function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1dbe1c-b279-49a9-af92-ff79fab7d0ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def cdc_merge(self, full_table_bronze: str, full_table_silver: str, filter_date: str):\n",
    "    pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43a1a1c7-dff4-475a-9be1-5ba144c739a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3 ‚Äî Execute merge _iteratively_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139ae61b-5c61-4261-9063-25509981e8d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT DISTINCT CAST(updated_at AS STRING) FROM {full_table_bronze} ORDER BY updated_at\"\n",
    "dates = [row['updated_at'] for row in spark.sql(query).collect()] \n",
    "print(dates)\n",
    "\n",
    "for date in dates:\n",
    "    print(\"Performing CDC Merge:\", date)\n",
    "    mod3.cdc_merge(full_table_bronze, full_table_silver, date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28901d3e-d121-4309-99cd-ed3eee653e33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.4 ‚Äî Validate Data\n",
    "\n",
    "Let‚Äôs validate our CDC logic and schema evolution:\n",
    "- Visualize resulting data.\n",
    "- Check the number of active vs deleted rows.\n",
    "- Validate table history, there should be 1 merge operation per each file / date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f24f7b0d-f8f7-4a36-aa01-233db0242921",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760453388196}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {full_table_silver} ORDER BY sale_id\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c249eb78-901f-42d0-be5b-004ee4968b32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "  MIN(_file_name) AS min_file,\n",
    "  MAX(_file_name) AS max_file,\n",
    "  COUNT(*) AS total_rows,\n",
    "  SUM(CASE WHEN _is_active THEN 1 ELSE 0 END) AS active_rows,\n",
    "  COUNT(DISTINCT region) AS distinct_regions\n",
    "FROM {full_table_silver}\n",
    "\"\"\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "267837f5-075e-4ee8-94e6-6c914ae209e1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"operationParameters\":442,\"operationMetrics\":1500},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761232534592}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"DESCRIBE HISTORY {full_table_silver}\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5222f7a1-f9e5-4cc2-8f72-230445ad3b8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3 ‚Äî Optimize and Time Travel (OPTIONAL)\n",
    "\n",
    "Finally, we apply performance and maintenance commands:\n",
    "- `OPTIMIZE` with ZORDER for query speed (sale_id).\n",
    "- Demonstrate **time travel** by exploring previous table versions - e.g. first historic load.\n",
    "\n",
    ">**Key Note:**\n",
    ">- `ZORDER BY sale_id` co-locates data with similar sale_ids, speeding up point lookups and merge operations.\n",
    ">- Use the `DESCRIBE HISTORY` command to explore rollback scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de52fa7f-3d08-4608-930a-7590d64555e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"OPTIMIZE {full_table_silver} ZORDER BY sale_id\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76070446-8f32-4d7f-9cb7-6466cf12dbb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {full_table_silver} VERSION AS OF 1\"\n",
    "display(spark.sql(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc9ba872-1fc4-40e1-9d8a-f35d5207b238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reflection & Discussion\n",
    "\n",
    "1. **Soft vs. Hard Deletes:**  \n",
    "   - How would your MERGE logic change if you wanted to *physically remove* deleted records rather than marking them inactive?\n",
    "   - What would be the pros and cons in a data lake context?\n",
    "2. **Reprocessing and Checkpoints:**  \n",
    "   - If a new CDC file arrives late or you must re-run day 3, how could you ensure idempotency?  \n",
    "   - What metadata or checkpointing strategies could you implement to track the ‚Äúlast successfully processed‚Äù date or file?\n",
    "3. **Schema Evolution in Streaming Pipelines:**  \n",
    "   - How can you adapt this logic to Auto Loader in *continuous mode*?  \n",
    "   - What settings (`cloudFiles.schemaEvolutionMode`, `mergeSchema`) help keep the pipeline robust against schema drift?![](path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7ad24f9-ec42-494a-8ee8-0ad02d936fc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Tests\n",
    "\n",
    "TO DO:\n",
    "\n",
    "- Check if there are any failed tests and investigate their root cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55cc8595-ec63-4cd4-81fb-72d8fe81424e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from helpers import test_runner\n",
    "import os\n",
    "\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "os.environ[\"NOTEBOOK_NAME\"] = notebook_path.split(\"/\")[-1]\n",
    "\n",
    "test_runner.run()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8791394620388585,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3-cdc-merge",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
